---
title: "00.Introduction of Elastic Stack"
categories: 
  - ELK-Starter
tags:
  - ELK-Stack
  - Elasticsearch
  - Logstash
  - Kibana
  - Beats
last_modified_at: 2019-04-23T13:00:00+09:00
author_profile: false
sitemap :
  changefreq : daily
  priority : 1.0
sidebar:
  - nav: elk-nav
---

## 1. Overview
이번 시리즈에서는 `Elastic Stack`라고 불리는 로그 및 데이터 분석도구에 대한 내용을 다루려고 합니다.  
데이터를 저장하고 분석하는 역할을하는 `Elasticsearch`부터, 로그를 수집하고 전송하는 기능의 `Logstash`, 데이터 시각화 및 분석기능의 `Kibana`, 데이터 수집기능의 `Beats`까지 폭넓고 깊게 다룰것입니다.  
![image](https://user-images.githubusercontent.com/15958325/56702620-f4d96800-673f-11e9-8628-3c5c97389c85.png)  

먼저 튜토리얼로 넘어가기전에 `Elastic stack`이란 무엇인지, 어떤 역할을 하는지 짚고 넘어가도록 하겠습니다.  

## 2. Elastic Stack
세상에는 여러종류의 Data가 있습니다.  
예를 들어 어떤 마트의 고객정보들을 기록한 데이터를 생각해봅시다. 이러한 데이터들은 정보자체가 정형화되어 있습니다. 이름, 나이, 전화번호, 주소 등 각 마트에서 원하는 정보를 틀로 만들어 새로운 정보들을 틀안에 잘 끼워넣을 수 있게할 수 있습니다.  
다른 예로, IT 인프라에서 발생하는 모든 상황의 데이터인 Log 데이터는 발생하는 모든 행위와 그 이벤트 정보를 전부 담고있기 때문에 해당 인프라를 개발한 개발자에 따라 형식이 전부 다릅니다. **즉 Log데이터는 정형화되어있지 않습니다.**  
때문에 기존의 관계형 DataBase로는 비정형 데이터를 분석하기가 굉장히 까다롭습니다.  

>### TIP. Log Data의 분석이 중요한 이유  
>대표적인 비정형 데이터인 Log데이터는 인프라를 사용하며 발생하는 모든 정보를 담고있습니다. 사용자의 사용패턴을 파악해서 더 나은 서비스를 제공하기 위해, 에러의 원인을 분석하기 위해, 또는 자원의 사용량을 체크하고 모니터링 하기 위해 등등 다양한 요구사항을 해결하기 위해 Log데이터의 분석은 필수적입니다.   

### 분석 어떻게?
일반적으로 데이터 분석은 데이터 소스 수집, 저장, 처리, 분석, 표현의 프로세스를 거칩니다.  

`Elastic Stack`은 다음 사진과 같이 데이터 분석에 대한 모든 프로세스를 제공합니다. 또한 구축이 굉장히 쉽고 강력하며 무료이기 때문에 잠재적 가치가 매우 큽니다. 최근에는 Elastic Stack에 `X-Pack`이라는 머신 러닝 기법을 적용한 플러그인을 제공해 분석의 퀄리티를 더욱 올리고 있습니다.

![image](https://user-images.githubusercontent.com/15958325/56786095-a789f300-6832-11e9-9823-21f49b900590.png)  


### Elastic Stack은 무엇?
Elastic Stack은 어떤 하나의 통합된 솔루션이 아니라 4개의 product로 구성되어 있습니다.  
기존에는 `ElasticSearch` + `Logstash` + `Kibana`를 서로 묶어서 ELK라는 서비스명으로 제공하였으나, 5.0.0버전부터 `Beats`가 추가되어 Elastic Stack이라는 이름으로 변경되게 되었습니다.  
[참고링크](https://www.elastic.co/kr/blog/heya-elastic-stack-and-x-pack)  


## 3. ElasticSearch
Apache Lucene 기반의 Java 오픈소스 분산 **검색 엔진**입니다.  
1. Full Text 검색 가능
2. RESTful
3. 대량의 데이터를 거의 실시간(NRT, Near Real Time)으로 저장, 검색 및 분석가능

> You Know, for Search.

### 관계형 DB와의 비교
데이터를 저장하고 검색하는 기능이다보니 기존의 관계형 DB와 비교하면 용어들을 좀 더 쉽게 이해할 수 있습니다.  

Relational Database|ElasticSearch
---------|----------
Database|Index
Row|Document
Column|Field
Index|Analyze
Primary Key|_id
Schema|Mapping
Physical Partition|Shard
Logical Partition|Route
Relational|Parent/Child, Nested
SQL|Query DSL

그럼 각각의 용어들을 더 살펴보도록 하겠습니다.  

### 용어
아래의 사진은 이해를 돕기위한 ElasticSearch의 전체적인 아키텍처입니다.  
![image](https://user-images.githubusercontent.com/15958325/56788933-a4473500-683b-11e9-9f95-9088234f110b.png)  

공식문서 : [Basic Concept](https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started-concepts.html)  

#### Near Realtime (NRT)
ElasticSearch는 NRT 플랫폼입니다. 문서를 indexing할때부터 검색이 가능해질때까지 약간의 지연시간(일반적으로 1초)이 있다는 것을 의미합니다.  

#### Cluster
ElasticSearch에서 가장 큰 개념이며 모든 노드(서버)의 모음입니다. 기본적으로 고유한 이름으로 식별됩니다.  

#### Node
cluster의 indexing및 검색기능에 참여하는 단일 서버입니다. cluster와 마찬가지로 Node가 생성될때 임의로 할당되는 고유 id로 식별됩니다. 기본값인 id를 사용하지 않을 경우 원하는 이름으로 정의할 수 있습니다.  

#### Document
indexing할 수 있는 데이터의 기본 단위입니다. JSON으로 표현되어 있으며, index내에서 원하는 만큼의 Document를 저장할 수 있습니다.  

#### Type
다른 타입의 document를 하나의 index에 저장할 수 있게 index를 구분할 때 사용되는 유형입니다.  
> 하지만 ElasticSearch 6.0.0부터 사라지는 항목입니다.  
> 다음 링크를 참조해 주세요.  --> [Removal of mapping types](https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html)  

#### Index  
Document들의 집합입니다. index는 이름으로 식별되며 `indexing`, `search`, `update`, `delete`작업을 수행할때 사용됩니다.  
단일 cluster에서 원하는 만큼의 인덱스를 정의할 수 있습니다.

#### Shards
Index는 대량의 데이터를 저장할 수 있습니다. 하지만 이러한 대량의 데이터를 검색해야된다거나 HW제한을 초과하는 용량을 담아야 한다면 단일노드에서 작업하는 것은 별로 좋지 않을 수 있습니다.  
이러한 문제를 해결하기 위해 Index를 여러 조각으로 분할하여 저장할 수 있습니다. 분할된 조각을 `Shard`라고 하며 기본적으로는 1개의 `Shard`가 존재합니다.  
검색 성능 향상을 위해 cluster의 `Shard`개수를 조정하는 튜닝을 하기도 합니다.  

#### Replicas
노드나 `shard`를 손실했을 경우 데이터의 고가용성을 제공합니다. 때문에 `shard`와 `replica`는 동일한 노드에 할당되지 않습니다.  
또한 검색할때 모든 `replica`에서도 병렬으로 실행할 수 있으므로, 처리량을 높일 수 있습니다.  
index를 정의할 때, `shard`와 `replica`의 수를 정의할 수 있습니다. 그리고 index를 생성하고 난 후에도 언제든지 동적으로 `replica`의 수를 변경할 수 있습니다. 하지만 `shard`의 수를 동적으로 변경하는 것은 약간 어렵습니다.  

![image](https://user-images.githubusercontent.com/15958325/56894182-0adc8500-6ac0-11e9-86a2-177c77345a65.png)  


## 4. Logstash
다양한 플러그인을 이용해 데이터 집계 및 보관, 서버 데이터 처리, 파이프라인으로 데이터를 받아 필터를 통해 변환 후, 저장소에 전송하는 역할을 맡고있습니다.  

### 용어
![image](https://user-images.githubusercontent.com/15958325/56935648-65f89100-6b2d-11e9-94dc-3ebae2ef36da.png)  

#### Input
`Logstash` 파이프 라인에 데이터를 가져오는 부분입니다. `Beats`, `file`, `syslog`등 다양한 입력을 지원하기 때문에 시스템상에 다양한 형태로 보관된 데이터들을 쉽게 가져올 수 있습니다.  
> input plugin 정보 : [link](https://www.elastic.co/guide/en/logstash/current/input-plugins.html)

#### filter
`Logstash` 파이프라인 중 중간 처리 장치입니다.  
데이터가 이동하는 과정에서 구문분석과 변환을 할 수 있습니다.  

> filter plugin 정보 : [link](https://www.elastic.co/guide/en/logstash/current/filter-plugins.html)  

#### output
`Logstash` 파이프라인의 최종 단계입니다. 데이터를 저장소에 전송하는 역할을 맡고있습니다.  
`ElasticSearch`말고도 여러 저장소를 지원하고 있기 때문에 폭넓은 사용을 가능하게 합니다.  
>output plugin 정보 : [link](https://www.elastic.co/guide/en/logstash/current/output-plugins.html)

#### codec
입력 또는 출력의 일부로 작동할 수 있는 스트림 필터입니다. 자주 사용하는 codec에는 json, msgpack, plain이 있습니다.  
>예) json : JSON형식의 데이터를 인코딩하거나 디코딩합니다.  


### 특징
#### 확장성
`Logstash`에는 플러그인으로 확장 가능한 프레임워크가 200개 이상이 있습니다.   
다양한 입력과 필터, 출력을 자유롭게 조절할 수 있습니다.  

#### 안정성&보안성
`Logstash` 노드가 다운되어도, `Logstash`는 Persistent Queue를 사용하여 현재 처리되고 있는 이벤트에 대해 최소 1회 전송을 보장합니다.  
성공적으로 처리되지 않은 이벤트는 검증 및 재전송을 위해 Dead Letter Queue로 분류할 수 있습니다.  
추가로, `Beats`로 데이터를 수집하는 경우 데이터 암호화가 가능하며, `ElasticSearch` 보안 클러스터와 완전히 통합될 수 있습니다.

#### 모니터링
다양한 목적으로 활용되는 Logstash의 파이프라인은 잘 정리해두지 않으면 금세 복잡해져서 쉽게 파악하기가 어려울 수 있습니다.  
Kibana와 결합하면 실행중인 Logstash노드를 손쉽게 파악할 수 있습니다.  
![image](https://user-images.githubusercontent.com/15958325/56935788-69404c80-6b2e-11e9-9b79-930e92e77c52.png)  

## 5. Kibana

## 6. Beats

----